{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Arithmetic Logic Units",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/juliusfrost/Research-Paper-Implementations/blob/master/Neural_Arithmetic_Logic_Units.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ALGlVINoC3UB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Neural Arithmetic Logic Units\n",
        "\n",
        "https://arxiv.org/abs/1808.00508"
      ]
    },
    {
      "metadata": {
        "id": "DPdtNeeMtJfC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DY4poazuDJBK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The NALU layer"
      ]
    },
    {
      "metadata": {
        "id": "R5CKvQu4tZQ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NALU(tf.keras.layers.Layer):\n",
        "  def __init__(self, output_dim, **kwargs):\n",
        "    self.output_dim = output_dim\n",
        "    super(NALU, self).__init__(**kwargs)\n",
        "    \n",
        "  def build(self, input_shape):\n",
        "    shape = tf.TensorShape((input_shape[1], self.output_dim))\n",
        "    initializer = tf.keras.initializers.RandomUniform(minval=-1, maxval=1)\n",
        "    self.G = self.add_weight(name='G', shape=shape, initializer=initializer, trainable=True)\n",
        "    self.W_hat = self.add_weight(name='W_hat', shape=shape, initializer=initializer, trainable=True)\n",
        "    self.M_hat = self.add_weight(name='M_hat', shape=shape, initializer=initializer, trainable=True)\n",
        "    \n",
        "    super(NALU, self).build(input_shape)\n",
        "    \n",
        "    \n",
        "  def call(self, x):\n",
        "    W = tf.tanh(self.W_hat) * tf.sigmoid(self.M_hat)\n",
        "    a = tf.matmul(x, W)\n",
        "    g = tf.sigmoid(tf.matmul(x, self.G))\n",
        "    m = tf.exp(tf.matmul(tf.log(tf.abs(x)+0.0001), W))\n",
        "    y = g*a + (1-g)*m\n",
        "    return y\n",
        "  \n",
        "  def compute_output_shape(self, input_shape):\n",
        "    shape = tf.TensorShape(input_shape).as_list()\n",
        "    shape[-1] = self.output_dim\n",
        "    return tf.TensorShape(shape)\n",
        "  \n",
        "  def get_config(self):\n",
        "    base_config = super(NALU, self).get_config()\n",
        "    base_config['output_dim'] = self.output_dim\n",
        "    \n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    return cls(**config)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SRLRfk0iDX3V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Train"
      ]
    },
    {
      "metadata": {
        "id": "T4GdljwUDaOv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###seed"
      ]
    },
    {
      "metadata": {
        "id": "5uDGJ_i9xM8o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.random import seed\n",
        "seed(42)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "InXBZuPHDfSv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###build model"
      ]
    },
    {
      "metadata": {
        "id": "vGAoJF3Q02yu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = np.random.random((10000, 2))*20-10\n",
        "y_train = x_train[:,0] + x_train[:,1]\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    NALU(8),\n",
        "    NALU(1),\n",
        "])\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
        "              loss='mse',       # mean squared error\n",
        "              metrics=['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ynx8rOMGDikR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###train model"
      ]
    },
    {
      "metadata": {
        "id": "UgH0xo_BfPtv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3434
        },
        "outputId": "12d91fff-c091-48b1-e3d5-e2a3860059fc"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, batch_size=32, epochs=100, verbose=1)"
      ],
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10000/10000 [==============================] - 2s 175us/step - loss: 57.6385 - mean_absolute_error: 6.0693\n",
            "Epoch 2/100\n",
            "10000/10000 [==============================] - 2s 170us/step - loss: 45.6031 - mean_absolute_error: 5.2586\n",
            "Epoch 3/100\n",
            "10000/10000 [==============================] - 2s 173us/step - loss: 34.2341 - mean_absolute_error: 4.4540\n",
            "Epoch 4/100\n",
            "10000/10000 [==============================] - 2s 161us/step - loss: 22.7761 - mean_absolute_error: 3.5172\n",
            "Epoch 5/100\n",
            "10000/10000 [==============================] - 2s 152us/step - loss: 17.1324 - mean_absolute_error: 2.9011\n",
            "Epoch 6/100\n",
            "10000/10000 [==============================] - 2s 153us/step - loss: 11.5059 - mean_absolute_error: 2.4834\n",
            "Epoch 7/100\n",
            "10000/10000 [==============================] - 2s 165us/step - loss: 10.2021 - mean_absolute_error: 2.2094\n",
            "Epoch 8/100\n",
            "10000/10000 [==============================] - 2s 171us/step - loss: 7.3893 - mean_absolute_error: 1.9676\n",
            "Epoch 9/100\n",
            "10000/10000 [==============================] - 2s 172us/step - loss: 6.0690 - mean_absolute_error: 1.7652\n",
            "Epoch 10/100\n",
            "10000/10000 [==============================] - 2s 173us/step - loss: 5.0167 - mean_absolute_error: 1.5873\n",
            "Epoch 11/100\n",
            "10000/10000 [==============================] - 2s 171us/step - loss: 4.1771 - mean_absolute_error: 1.4301\n",
            "Epoch 12/100\n",
            "10000/10000 [==============================] - 2s 170us/step - loss: 3.5495 - mean_absolute_error: 1.3093\n",
            "Epoch 13/100\n",
            "10000/10000 [==============================] - 2s 162us/step - loss: 3.1379 - mean_absolute_error: 1.2043\n",
            "Epoch 14/100\n",
            "10000/10000 [==============================] - 2s 160us/step - loss: 2.8049 - mean_absolute_error: 1.1108\n",
            "Epoch 15/100\n",
            "10000/10000 [==============================] - 2s 163us/step - loss: 2.5092 - mean_absolute_error: 1.0282\n",
            "Epoch 16/100\n",
            "10000/10000 [==============================] - 2s 161us/step - loss: 2.2459 - mean_absolute_error: 0.9584\n",
            "Epoch 17/100\n",
            "10000/10000 [==============================] - 2s 154us/step - loss: 1.9859 - mean_absolute_error: 0.8886\n",
            "Epoch 18/100\n",
            "10000/10000 [==============================] - 2s 151us/step - loss: 1.7567 - mean_absolute_error: 0.8323\n",
            "Epoch 19/100\n",
            "10000/10000 [==============================] - 2s 152us/step - loss: 1.5620 - mean_absolute_error: 0.7837\n",
            "Epoch 20/100\n",
            "10000/10000 [==============================] - 2s 166us/step - loss: 1.3121 - mean_absolute_error: 0.7235\n",
            "Epoch 21/100\n",
            "10000/10000 [==============================] - 2s 169us/step - loss: 1.1312 - mean_absolute_error: 0.6635\n",
            "Epoch 22/100\n",
            "10000/10000 [==============================] - 2s 169us/step - loss: 0.9525 - mean_absolute_error: 0.6093\n",
            "Epoch 23/100\n",
            "10000/10000 [==============================] - 2s 171us/step - loss: 0.7888 - mean_absolute_error: 0.5555\n",
            "Epoch 24/100\n",
            "10000/10000 [==============================] - 2s 169us/step - loss: 0.6568 - mean_absolute_error: 0.5072\n",
            "Epoch 25/100\n",
            "10000/10000 [==============================] - 2s 176us/step - loss: 0.5407 - mean_absolute_error: 0.4621\n",
            "Epoch 26/100\n",
            "10000/10000 [==============================] - 2s 171us/step - loss: 0.4399 - mean_absolute_error: 0.4204\n",
            "Epoch 27/100\n",
            "10000/10000 [==============================] - 2s 176us/step - loss: 0.3556 - mean_absolute_error: 0.3802\n",
            "Epoch 28/100\n",
            "10000/10000 [==============================] - 2s 177us/step - loss: 0.2871 - mean_absolute_error: 0.3445\n",
            "Epoch 29/100\n",
            "10000/10000 [==============================] - 2s 166us/step - loss: 0.2332 - mean_absolute_error: 0.3124\n",
            "Epoch 30/100\n",
            "10000/10000 [==============================] - 2s 154us/step - loss: 0.1920 - mean_absolute_error: 0.2872\n",
            "Epoch 31/100\n",
            "10000/10000 [==============================] - 2s 154us/step - loss: 0.1600 - mean_absolute_error: 0.2664\n",
            "Epoch 32/100\n",
            "10000/10000 [==============================] - 2s 167us/step - loss: 0.1343 - mean_absolute_error: 0.2464\n",
            "Epoch 33/100\n",
            "10000/10000 [==============================] - 2s 174us/step - loss: 0.1134 - mean_absolute_error: 0.2275\n",
            "Epoch 34/100\n",
            "10000/10000 [==============================] - 2s 171us/step - loss: 0.0961 - mean_absolute_error: 0.2096\n",
            "Epoch 35/100\n",
            "10000/10000 [==============================] - 2s 167us/step - loss: 0.0812 - mean_absolute_error: 0.1920\n",
            "Epoch 36/100\n",
            "10000/10000 [==============================] - 2s 169us/step - loss: 0.0687 - mean_absolute_error: 0.1761\n",
            "Epoch 37/100\n",
            "10000/10000 [==============================] - 2s 173us/step - loss: 0.0583 - mean_absolute_error: 0.1618\n",
            "Epoch 38/100\n",
            "10000/10000 [==============================] - 2s 166us/step - loss: 0.0499 - mean_absolute_error: 0.1508\n",
            "Epoch 39/100\n",
            "10000/10000 [==============================] - 2s 164us/step - loss: 0.0470 - mean_absolute_error: 0.1444\n",
            "Epoch 40/100\n",
            "10000/10000 [==============================] - 2s 162us/step - loss: 0.0393 - mean_absolute_error: 0.1375\n",
            "Epoch 41/100\n",
            "10000/10000 [==============================] - 2s 165us/step - loss: 0.0353 - mean_absolute_error: 0.1326\n",
            "Epoch 42/100\n",
            "10000/10000 [==============================] - 2s 155us/step - loss: 0.0320 - mean_absolute_error: 0.1276\n",
            "Epoch 43/100\n",
            "10000/10000 [==============================] - 2s 155us/step - loss: 0.0288 - mean_absolute_error: 0.1221\n",
            "Epoch 44/100\n",
            "10000/10000 [==============================] - 2s 152us/step - loss: 0.0262 - mean_absolute_error: 0.1175\n",
            "Epoch 45/100\n",
            "10000/10000 [==============================] - 2s 172us/step - loss: 0.0237 - mean_absolute_error: 0.1127\n",
            "Epoch 46/100\n",
            "10000/10000 [==============================] - 2s 174us/step - loss: 0.0215 - mean_absolute_error: 0.1078\n",
            "Epoch 47/100\n",
            "10000/10000 [==============================] - 2s 170us/step - loss: 0.0194 - mean_absolute_error: 0.1025\n",
            "Epoch 48/100\n",
            "10000/10000 [==============================] - 2s 171us/step - loss: 0.0174 - mean_absolute_error: 0.0974\n",
            "Epoch 49/100\n",
            "10000/10000 [==============================] - 2s 170us/step - loss: 0.0155 - mean_absolute_error: 0.0914\n",
            "Epoch 50/100\n",
            "10000/10000 [==============================] - 2s 172us/step - loss: 0.0140 - mean_absolute_error: 0.0870\n",
            "Epoch 51/100\n",
            "10000/10000 [==============================] - 2s 170us/step - loss: 0.0124 - mean_absolute_error: 0.0817\n",
            "Epoch 52/100\n",
            "10000/10000 [==============================] - 2s 170us/step - loss: 0.0109 - mean_absolute_error: 0.0761\n",
            "Epoch 53/100\n",
            "10000/10000 [==============================] - 2s 175us/step - loss: 0.0096 - mean_absolute_error: 0.0709\n",
            "Epoch 54/100\n",
            "10000/10000 [==============================] - 2s 168us/step - loss: 0.0085 - mean_absolute_error: 0.0666\n",
            "Epoch 55/100\n",
            "10000/10000 [==============================] - 2s 157us/step - loss: 0.0075 - mean_absolute_error: 0.0622\n",
            "Epoch 56/100\n",
            "10000/10000 [==============================] - 2s 154us/step - loss: 0.0066 - mean_absolute_error: 0.0583\n",
            "Epoch 57/100\n",
            "10000/10000 [==============================] - 2s 161us/step - loss: 0.0058 - mean_absolute_error: 0.0544\n",
            "Epoch 58/100\n",
            "10000/10000 [==============================] - 2s 168us/step - loss: 0.0051 - mean_absolute_error: 0.0509\n",
            "Epoch 59/100\n",
            "10000/10000 [==============================] - 2s 169us/step - loss: 0.0045 - mean_absolute_error: 0.0476\n",
            "Epoch 60/100\n",
            "10000/10000 [==============================] - 2s 170us/step - loss: 0.0040 - mean_absolute_error: 0.0444\n",
            "Epoch 61/100\n",
            "10000/10000 [==============================] - 2s 176us/step - loss: 0.0035 - mean_absolute_error: 0.0416\n",
            "Epoch 62/100\n",
            "10000/10000 [==============================] - 2s 178us/step - loss: 0.0031 - mean_absolute_error: 0.0388\n",
            "Epoch 63/100\n",
            "10000/10000 [==============================] - 2s 167us/step - loss: 0.0026 - mean_absolute_error: 0.0356\n",
            "Epoch 64/100\n",
            "10000/10000 [==============================] - 2s 164us/step - loss: 0.0023 - mean_absolute_error: 0.0329\n",
            "Epoch 65/100\n",
            "10000/10000 [==============================] - 2s 164us/step - loss: 0.0020 - mean_absolute_error: 0.0307\n",
            "Epoch 66/100\n",
            "10000/10000 [==============================] - 2s 161us/step - loss: 0.0018 - mean_absolute_error: 0.0287\n",
            "Epoch 67/100\n",
            "10000/10000 [==============================] - 2s 156us/step - loss: 0.0016 - mean_absolute_error: 0.0273\n",
            "Epoch 68/100\n",
            "10000/10000 [==============================] - 2s 155us/step - loss: 0.0015 - mean_absolute_error: 0.0260\n",
            "Epoch 69/100\n",
            "10000/10000 [==============================] - 2s 157us/step - loss: 0.0014 - mean_absolute_error: 0.0249\n",
            "Epoch 70/100\n",
            "10000/10000 [==============================] - 2s 169us/step - loss: 0.0013 - mean_absolute_error: 0.0236\n",
            "Epoch 71/100\n",
            "10000/10000 [==============================] - 2s 167us/step - loss: 0.0011 - mean_absolute_error: 0.0223\n",
            "Epoch 72/100\n",
            "10000/10000 [==============================] - 2s 167us/step - loss: 0.0011 - mean_absolute_error: 0.0212\n",
            "Epoch 73/100\n",
            "10000/10000 [==============================] - 2s 171us/step - loss: 9.7831e-04 - mean_absolute_error: 0.0204\n",
            "Epoch 74/100\n",
            "10000/10000 [==============================] - 2s 168us/step - loss: 9.0067e-04 - mean_absolute_error: 0.0195\n",
            "Epoch 75/100\n",
            "10000/10000 [==============================] - 2s 169us/step - loss: 8.3191e-04 - mean_absolute_error: 0.0187\n",
            "Epoch 76/100\n",
            "10000/10000 [==============================] - 2s 166us/step - loss: 7.6986e-04 - mean_absolute_error: 0.0180\n",
            "Epoch 77/100\n",
            "10000/10000 [==============================] - 2s 168us/step - loss: 7.1340e-04 - mean_absolute_error: 0.0173\n",
            "Epoch 78/100\n",
            "10000/10000 [==============================] - 2s 171us/step - loss: 6.5655e-04 - mean_absolute_error: 0.0164\n",
            "Epoch 79/100\n",
            "10000/10000 [==============================] - 2s 168us/step - loss: 6.1156e-04 - mean_absolute_error: 0.0159\n",
            "Epoch 80/100\n",
            "10000/10000 [==============================] - 2s 152us/step - loss: 5.6504e-04 - mean_absolute_error: 0.0152\n",
            "Epoch 81/100\n",
            "10000/10000 [==============================] - 2s 154us/step - loss: 5.2524e-04 - mean_absolute_error: 0.0146\n",
            "Epoch 82/100\n",
            "10000/10000 [==============================] - 2s 158us/step - loss: 4.8848e-04 - mean_absolute_error: 0.0141\n",
            "Epoch 83/100\n",
            "10000/10000 [==============================] - 2s 167us/step - loss: 4.5212e-04 - mean_absolute_error: 0.0135\n",
            "Epoch 84/100\n",
            "10000/10000 [==============================] - 2s 172us/step - loss: 4.2461e-04 - mean_absolute_error: 0.0130\n",
            "Epoch 85/100\n",
            "10000/10000 [==============================] - 2s 168us/step - loss: 3.9362e-04 - mean_absolute_error: 0.0125\n",
            "Epoch 86/100\n",
            "10000/10000 [==============================] - 2s 173us/step - loss: 3.6360e-04 - mean_absolute_error: 0.0119\n",
            "Epoch 87/100\n",
            "10000/10000 [==============================] - 2s 171us/step - loss: 3.4132e-04 - mean_absolute_error: 0.0115\n",
            "Epoch 88/100\n",
            "10000/10000 [==============================] - 2s 166us/step - loss: 3.1801e-04 - mean_absolute_error: 0.0111\n",
            "Epoch 89/100\n",
            "10000/10000 [==============================] - 2s 158us/step - loss: 2.9623e-04 - mean_absolute_error: 0.0106\n",
            "Epoch 90/100\n",
            "10000/10000 [==============================] - 2s 161us/step - loss: 2.7610e-04 - mean_absolute_error: 0.0103\n",
            "Epoch 91/100\n",
            "10000/10000 [==============================] - 2s 163us/step - loss: 2.5760e-04 - mean_absolute_error: 0.0099\n",
            "Epoch 92/100\n",
            "10000/10000 [==============================] - 2s 159us/step - loss: 2.4333e-04 - mean_absolute_error: 0.0096\n",
            "Epoch 93/100\n",
            "10000/10000 [==============================] - 2s 153us/step - loss: 2.2857e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 94/100\n",
            "10000/10000 [==============================] - 2s 153us/step - loss: 2.1446e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 95/100\n",
            "10000/10000 [==============================] - 2s 166us/step - loss: 2.0179e-04 - mean_absolute_error: 0.0086\n",
            "Epoch 96/100\n",
            "10000/10000 [==============================] - 2s 166us/step - loss: 1.8763e-04 - mean_absolute_error: 0.0082\n",
            "Epoch 97/100\n",
            "10000/10000 [==============================] - 2s 174us/step - loss: 1.7630e-04 - mean_absolute_error: 0.0079\n",
            "Epoch 98/100\n",
            "10000/10000 [==============================] - 2s 173us/step - loss: 1.6822e-04 - mean_absolute_error: 0.0078\n",
            "Epoch 99/100\n",
            "10000/10000 [==============================] - 2s 173us/step - loss: 1.5600e-04 - mean_absolute_error: 0.0074\n",
            "Epoch 100/100\n",
            "10000/10000 [==============================] - 2s 171us/step - loss: 1.4695e-04 - mean_absolute_error: 0.0072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa9aa74a668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 324
        }
      ]
    },
    {
      "metadata": {
        "id": "yEzk0wFFDm1I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Test"
      ]
    },
    {
      "metadata": {
        "id": "5eRdRDC-DubD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Even though we trained on values in the range (-10,10), the model is great at extrapolating to values in the range (-100,100)"
      ]
    },
    {
      "metadata": {
        "id": "j8tfU33pctgs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "0cea11ec-2995-407c-a57f-6b5fd48ff76a"
      },
      "cell_type": "code",
      "source": [
        "r = 100\n",
        "x_test = np.random.random((10, 2)) *r*2 - r\n",
        "y_test = x_test[:,0] + x_test[:,1]\n",
        "\n",
        "for i,y in enumerate(model.predict(x_test)):\n",
        "  print(str(round(x_test[i][0],2)) + ' + ' + str(round(x_test[i][1],2)) + '\\npredicted: ' + str(round(y[0],2)) + '\\nactual: ' + str(round(y_test[i],2)) + '\\n')"
      ],
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-57.39 + -84.0\n",
            "predicted: -141.01\n",
            "actual: -141.39\n",
            "\n",
            "18.67 + -56.1\n",
            "predicted: -37.2\n",
            "actual: -37.43\n",
            "\n",
            "68.94 + 57.42\n",
            "predicted: 126.01\n",
            "actual: 126.35\n",
            "\n",
            "3.09 + 28.73\n",
            "predicted: 31.73\n",
            "actual: 31.82\n",
            "\n",
            "64.61 + 93.88\n",
            "predicted: 158.03\n",
            "actual: 158.5\n",
            "\n",
            "-68.33 + 34.98\n",
            "predicted: -33.48\n",
            "actual: -33.34\n",
            "\n",
            "87.28 + 86.11\n",
            "predicted: 172.87\n",
            "actual: 173.39\n",
            "\n",
            "82.12 + 85.11\n",
            "predicted: 166.74\n",
            "actual: 167.23\n",
            "\n",
            "-14.31 + 6.01\n",
            "predicted: -8.32\n",
            "actual: -8.3\n",
            "\n",
            "96.28 + -48.89\n",
            "predicted: 47.07\n",
            "actual: 47.4\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WyGPon3Di8CZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}